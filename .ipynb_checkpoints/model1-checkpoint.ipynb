{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847b95db-10ce-4d2e-95c2-c94b0b07bc95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79d7eb0b-a90f-4db0-9861-7c9e93e9e8ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data cleaning and preprocessing complete.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'Bengaluru_House_Data.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Extract number of bedrooms from 'size'\n",
    "data['BHK'] = data['size'].apply(lambda x: int(x.split(' ')[0]) if isinstance(x, str) else None)\n",
    "\n",
    "# Convert 'total_sqft' to numeric (handle ranges like \"2100 - 2850\")\n",
    "def convert_sqft_to_num(x):\n",
    "    try:\n",
    "        return float(x)\n",
    "    except:\n",
    "        if '-' in str(x):\n",
    "            parts = x.split('-')\n",
    "            return (float(parts[0]) + float(parts[1])) / 2\n",
    "        return None\n",
    "\n",
    "data['total_sqft'] = data['total_sqft'].apply(convert_sqft_to_num)\n",
    "\n",
    "# Define imputers for numerical and categorical columns\n",
    "num_imputer = SimpleImputer(strategy='mean')\n",
    "cat_imputer = SimpleImputer(strategy='most_frequent')\n",
    "\n",
    "# Separate numerical and categorical columns\n",
    "num_cols = data.select_dtypes(include=['float64', 'int64']).columns\n",
    "cat_cols = data.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Impute missing values\n",
    "data[num_cols] = num_imputer.fit_transform(data[num_cols])\n",
    "data[cat_cols] = cat_imputer.fit_transform(data[cat_cols])\n",
    "\n",
    "print(\"Data cleaning and preprocessing complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae55324-c6bd-4a9d-9693-ea0ceb2b04b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'Bengaluru_House_Data.csv'  # Update this path to your local dataset path\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Ensure price column is numeric\n",
    "data['price'] = pd.to_numeric(data['price'], errors='coerce')\n",
    "\n",
    "# Extract number of bedrooms from 'size' column and create 'BHK'\n",
    "data['BHK'] = data['size'].apply(lambda x: int(x.split(' ')[0]) if isinstance(x, str) else None)\n",
    "\n",
    "# Distribution of Price\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(data['price'], bins=30, kde=True)\n",
    "plt.title('Distribution of House Prices')\n",
    "plt.xlabel('Price (in Lakhs)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.savefig('price_distribution.png')  # Saves the image locally\n",
    "plt.close()\n",
    "\n",
    "# Distribution of Total Square Feet\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(data['total_sqft'], bins=30, kde=True)\n",
    "plt.title('Distribution of Total Square Feet')\n",
    "plt.xlabel('Total Square Feet')\n",
    "plt.ylabel('Frequency')\n",
    "plt.savefig('total_sqft_distribution.png')\n",
    "plt.close()\n",
    "\n",
    "# Distribution of Bathrooms\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(data['bath'], bins=30, kde=True)\n",
    "plt.title('Distribution of Bathrooms')\n",
    "plt.xlabel('Number of Bathrooms')\n",
    "plt.ylabel('Frequency')\n",
    "plt.savefig('bathroom_distribution.png')\n",
    "plt.close()\n",
    "\n",
    "# Correlation Heatmap (for numerical features)\n",
    "plt.figure(figsize=(12, 8))\n",
    "numeric_data = data.select_dtypes(include=[float, int])\n",
    "sns.heatmap(numeric_data.corr(), annot=True, cmap='coolwarm', vmin=-1, vmax=1, center=0)\n",
    "plt.title('Correlation Heatmap')\n",
    "plt.savefig('correlation_heatmap.png')\n",
    "plt.close()\n",
    "\n",
    "# Bar chart of average price by BHK\n",
    "plt.figure(figsize=(12, 6))\n",
    "average_price_by_bhk = data.groupby('BHK')['price'].mean().sort_values()\n",
    "sns.barplot(x=average_price_by_bhk.index, y=average_price_by_bhk.values)\n",
    "plt.title('Average Price by BHK')\n",
    "plt.xlabel('BHK')\n",
    "plt.ylabel('Average Price (in Lakhs)')\n",
    "plt.savefig('average_price_by_bhk.png')\n",
    "plt.close()\n",
    "\n",
    "# Bar chart of number of properties by location (Top 10 locations)\n",
    "plt.figure(figsize=(12, 6))\n",
    "top_locations = data['location'].value_counts().nlargest(10)\n",
    "sns.barplot(x=top_locations.index, y=top_locations.values)\n",
    "plt.title('Number of Properties by Location (Top 10)')\n",
    "plt.xlabel('Location')\n",
    "plt.ylabel('Number of Properties')\n",
    "plt.xticks(rotation=45)\n",
    "plt.savefig('properties_by_location.png')\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "beb65095-6148-4006-90a3-aea1503a9e4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature engineering complete.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Create 'price_per_sqft' feature\n",
    "data['price_per_sqft'] = data['price'] / data['total_sqft']\n",
    "\n",
    "# Log-transform 'price' to handle skewness\n",
    "data['log_price'] = np.log1p(data['price'])\n",
    "\n",
    "# One-hot encoding for categorical columns (area_type and location)\n",
    "data = pd.get_dummies(data, columns=['area_type', 'location'], drop_first=True)\n",
    "\n",
    "print(\"Feature engineering complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee53de37-4071-48bc-a570-8d0175c41fd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature columns used for training: ['location', 'BHK', 'total_sqft', 'bath', 'balcony']\n",
      "Model training complete.\n",
      "Train R² Score: 0.9623\n",
      "Test R² Score: 0.7760\n",
      "Train Mean Squared Error: 0.0191\n",
      "Test Mean Squared Error: 0.1153\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import joblib\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'Bengaluru_House_Data.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Extract number of bedrooms from 'size'\n",
    "data['BHK'] = data['size'].apply(lambda x: int(x.split(' ')[0]) if isinstance(x, str) else None)\n",
    "\n",
    "# Function to convert 'total_sqft' to numeric (handling ranges and non-numeric values)\n",
    "def convert_sqft_to_num(x):\n",
    "    try:\n",
    "        return float(x)\n",
    "    except ValueError:\n",
    "        if '-' in str(x):\n",
    "            parts = x.split('-')\n",
    "            return (float(parts[0]) + float(parts[1])) / 2\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "# Apply the conversion function to 'total_sqft'\n",
    "data['total_sqft'] = data['total_sqft'].apply(convert_sqft_to_num)\n",
    "\n",
    "# Drop rows where 'total_sqft' is still None\n",
    "data = data.dropna(subset=['total_sqft'])\n",
    "\n",
    "# Log-transform 'price' to handle skewness\n",
    "data['log_price'] = np.log1p(data['price'])\n",
    "\n",
    "# Label encode 'location'\n",
    "le = LabelEncoder()\n",
    "data['location'] = le.fit_transform(data['location'])\n",
    "\n",
    "# Save the Label Encoder for future use\n",
    "with open('label_encoders.pkl', 'wb') as le_file:\n",
    "    joblib.dump({'location': le}, le_file)\n",
    "\n",
    "# Define features and target (location is not numerical, so it won't be scaled)\n",
    "features = data[['location', 'BHK', 'total_sqft', 'bath', 'balcony']]\n",
    "target = data['log_price']\n",
    "\n",
    "# Separate the location (categorical) from the numerical features\n",
    "location = features[['location']].values  # Keeping 'location' aside for concatenation\n",
    "numerical_features = features.drop('location', axis=1)\n",
    "\n",
    "# Get the updated list of feature columns\n",
    "feature_columns = list(features.columns)\n",
    "print(\"Feature columns used for training:\", feature_columns)\n",
    "with open('feature_columns.pkl', 'wb') as f:\n",
    "    joblib.dump(feature_columns, f)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train_num, X_test_num, y_train, y_test = train_test_split(numerical_features, target, test_size=0.2, random_state=42)\n",
    "X_train_loc, X_test_loc = train_test_split(location, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the scaler and standardize only the numerical features (excluding location)\n",
    "scaler = StandardScaler()\n",
    "X_train_num_scaled = scaler.fit_transform(X_train_num)\n",
    "X_test_num_scaled = scaler.transform(X_test_num)\n",
    "\n",
    "# Save the scaler for future use\n",
    "joblib.dump(scaler, 'scaler.pkl')\n",
    "\n",
    "# Concatenate the scaled numerical features with the location (encoded)\n",
    "X_train_scaled = np.concatenate([X_train_loc, X_train_num_scaled], axis=1)\n",
    "X_test_scaled = np.concatenate([X_test_loc, X_test_num_scaled], axis=1)\n",
    "\n",
    "# Initialize the model\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Save the model\n",
    "joblib.dump(model, 'house_price_model.pkl')\n",
    "\n",
    "# Model Evaluation\n",
    "y_train_pred = model.predict(X_train_scaled)\n",
    "y_test_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Calculate MSE and R² for training and test sets\n",
    "train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "train_r2 = r2_score(y_train, y_train_pred)\n",
    "test_r2 = r2_score(y_test, y_test_pred)\n",
    "\n",
    "# Output evaluation metrics\n",
    "print(\"Model training complete.\")\n",
    "print(f\"Train R² Score: {train_r2:.4f}\")\n",
    "print(f\"Test R² Score: {test_r2:.4f}\")\n",
    "print(f\"Train Mean Squared Error: {train_mse:.4f}\")\n",
    "print(f\"Test Mean Squared Error: {test_mse:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b311cc-5acd-40dd-b1a5-429bbcb5de4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Model loaded successfully\n",
      "INFO:__main__:Scaler loaded successfully\n",
      "INFO:__main__:Label encoders loaded successfully\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
      " * Running on http://127.0.0.1:5002\n",
      "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
      "INFO:werkzeug:127.0.0.1 - - [20/Sep/2024 07:37:36] \"GET / HTTP/1.1\" 200 -\n",
      "INFO:__main__:Received data: {'features': ['Electronic City Phase II', 2, 1056, 2, 1]}\n",
      "INFO:__main__:Raw features: ['Electronic City Phase II', 2, 1056, 2, 1]\n",
      "C:\\Users\\sridh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "INFO:__main__:Prediction: [3.8848991]\n",
      "INFO:werkzeug:127.0.0.1 - - [20/Sep/2024 07:37:41] \"POST /predict HTTP/1.1\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [20/Sep/2024 07:38:00] \"GET /analytics HTTP/1.1\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [20/Sep/2024 07:38:00] \"\u001b[36mGET /static/images/total_sqft_distribution.png HTTP/1.1\u001b[0m\" 304 -\n",
      "INFO:werkzeug:127.0.0.1 - - [20/Sep/2024 07:38:00] \"\u001b[36mGET /static/images/price_distribution.png HTTP/1.1\u001b[0m\" 304 -\n",
      "INFO:werkzeug:127.0.0.1 - - [20/Sep/2024 07:38:00] \"\u001b[36mGET /static/images/average_price_by_bhk.png HTTP/1.1\u001b[0m\" 304 -\n",
      "INFO:werkzeug:127.0.0.1 - - [20/Sep/2024 07:38:00] \"\u001b[36mGET /static/images/properties_by_location.png HTTP/1.1\u001b[0m\" 304 -\n",
      "INFO:werkzeug:127.0.0.1 - - [20/Sep/2024 07:38:00] \"\u001b[36mGET /static/images/bathroom_distribution.png HTTP/1.1\u001b[0m\" 304 -\n",
      "INFO:werkzeug:127.0.0.1 - - [20/Sep/2024 07:38:00] \"\u001b[36mGET /static/images/correlation_heatmap.png HTTP/1.1\u001b[0m\" 304 -\n",
      "INFO:__main__:Received data: {'features': ['Electronic City Phase II', 2, 1057, 3, 2]}\n",
      "INFO:__main__:Raw features: ['Electronic City Phase II', 2, 1057, 3, 2]\n",
      "C:\\Users\\sridh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "INFO:__main__:Prediction: [4.36324441]\n",
      "INFO:werkzeug:127.0.0.1 - - [20/Sep/2024 07:39:25] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request, jsonify, render_template\n",
    "import logging\n",
    "import joblib\n",
    "import numpy as np\n",
    "from flask_cors import CORS\n",
    "\n",
    "app = Flask(__name__)\n",
    "CORS(app)\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# Initialize global variables for model, scaler, and label encoders\n",
    "model = None\n",
    "scaler = None\n",
    "label_encoders = None\n",
    "\n",
    "# Load the trained model, scaler, and label encoders\n",
    "def load_artifacts():\n",
    "    global model, scaler, label_encoders\n",
    "    try:\n",
    "        with open('house_price_model.pkl', 'rb') as model_file:\n",
    "            model = joblib.load(model_file)\n",
    "            app.logger.info(\"Model loaded successfully\")\n",
    "        \n",
    "        with open('scaler.pkl', 'rb') as scaler_file:\n",
    "            scaler = joblib.load(scaler_file)\n",
    "            app.logger.info(\"Scaler loaded successfully\")\n",
    "\n",
    "        with open('label_encoders.pkl', 'rb') as encoders_file:\n",
    "            label_encoders = joblib.load(encoders_file)\n",
    "            app.logger.info(\"Label encoders loaded successfully\")\n",
    "\n",
    "    except Exception as e:\n",
    "        app.logger.error(f\"Error loading artifacts: {e}\")\n",
    "        raise e\n",
    "\n",
    "# Load artifacts when the application starts\n",
    "load_artifacts()\n",
    "\n",
    "# Home route\n",
    "@app.route('/')\n",
    "def home():\n",
    "    return render_template('index.html')\n",
    "\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "    try:\n",
    "        data = request.get_json()\n",
    "        app.logger.info('Received data: %s', data)\n",
    "\n",
    "        if not data or 'features' not in data:\n",
    "            raise ValueError(\"Invalid input data: 'features' key not found.\")\n",
    "\n",
    "        features = data['features']\n",
    "        app.logger.info('Raw features: %s', features)\n",
    "\n",
    "        # Load feature columns\n",
    "        with open('feature_columns.pkl', 'rb') as f:\n",
    "            feature_columns = joblib.load(f)\n",
    "\n",
    "        # Ensure the correct number of features are passed\n",
    "        if len(features) != len(feature_columns):\n",
    "            raise ValueError(f\"Invalid number of features provided. Expected {len(feature_columns)}, got {len(features)}.\")\n",
    "\n",
    "        # Extract and encode location\n",
    "        location = features[0]\n",
    "        if location not in label_encoders['location'].classes_:\n",
    "            raise ValueError(f\"Location '{location}' not recognized.\")\n",
    "        \n",
    "        location_encoded = label_encoders['location'].transform([location])[0]\n",
    "\n",
    "        # Extract and scale numerical features\n",
    "        numerical_features = np.array(features[1:]).reshape(1, -1)\n",
    "\n",
    "        # Scale numerical features\n",
    "        numerical_features_scaled = scaler.transform(numerical_features)\n",
    "\n",
    "        # Combine encoded location and scaled numerical features\n",
    "        final_features = np.concatenate([[location_encoded], numerical_features_scaled[0]])\n",
    "\n",
    "        # Predict using the model\n",
    "        prediction = model.predict([final_features])\n",
    "        app.logger.info('Prediction: %s', prediction)\n",
    "\n",
    "        # Convert log prediction back to normal price\n",
    "        predicted_price = np.expm1(prediction[0])  # Using expm1 since we log-transformed the price\n",
    "\n",
    "        return jsonify({'predicted_price': round(predicted_price, 2)})\n",
    "    except ValueError as ve:\n",
    "        error_message = f\"Value Error: {str(ve)}\"\n",
    "        app.logger.error(error_message)\n",
    "        return jsonify({'error': error_message}), 400\n",
    "    except Exception as e:\n",
    "        error_message = f\"Error during prediction: {str(e)}\"\n",
    "        app.logger.error(error_message)\n",
    "        return jsonify({'error': error_message}), 500\n",
    "\n",
    "# Analytics route\n",
    "@app.route('/analytics')\n",
    "def analytics():\n",
    "    return render_template('analytics.html')\n",
    "\n",
    "# Run the app locally\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True, port=5002, use_reloader=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60499f70-3b39-4e23-8e43-d558962dc489",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
